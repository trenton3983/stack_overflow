{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch, Rectangle, Polygon\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as tkr\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import mplfinance as mpf  # https://github.com/matplotlib/mplfinance\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from itertools import product, combinations, permutations, zip_longest, groupby\n",
    "import random\n",
    "from datetime import datetime, timedelta, date, timezone\n",
    "from datetime import time as dtime\n",
    "from collections import OrderedDict, defaultdict, Counter, namedtuple\n",
    "import re\n",
    "import requests\n",
    "import statsmodels.api as sm\n",
    "import calendar\n",
    "import scipy\n",
    "import json\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from ast import literal_eval  # use to eval a string as a list df['column'] = df['column'].apply(literal_eval)\n",
    "import math\n",
    "import time  # messes up from datetime import time\n",
    "import sys\n",
    "import string\n",
    "import json\n",
    "import sklearn\n",
    "import urllib\n",
    "import urllib3\n",
    "import psutil\n",
    "from typing import List, Tuple, Union  # used for type hints\n",
    "from gc import collect\n",
    "\n",
    "import pandas_datareader as web\n",
    "import natsort as ns\n",
    "import yfinance as yf\n",
    "# from stockstats import StockDataFrame as sdf  # dataframe wrapper for stock calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html#overview\n",
    "pd.set_option('display.max_columns', 700)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.min_rows', 10)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "# pd.set_option('precision', 5)\n",
    "# pd.reset_option('precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn')\n",
    "# plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "# plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.rcParams['savefig.facecolor'] = 'white'  # use to set the background color when saving a figure\n",
    "# sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Matplotlib and Ipython-notebook: Displaying exactly the figure that will be saved][1]\n",
    "\n",
    "  [1]: https://stackoverflow.com/questions/37864735/matplotlib-and-ipython-notebook-displaying-exactly-the-figure-that-will-be-save/37879281#37879281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colored Note Boxes\n",
    "\n",
    "- [The Ultimate Markdown Guide](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-success\">\n",
    "<b>Success:</b> This alert box indicates a successful or positive action.<b>Success:</b> This alert box indicates a successful or positive action.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-danger\">\n",
    "<b>Danger:</b> This alert box indicates a dangerous or potentially negative action.<b>Danger:</b> This alert box indicates a dangerous or potentially negative action.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-warning\">\n",
    "<b>Example:</b> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. Typically also used to display warning messages.<b>Example:</b> Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. Typically also used to display warning messages.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> Use blue boxes (alert-info) for tips and notes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use recursion to flatten the nested `dicts`\n",
    "\n",
    " - [Thinking Recursively in Python][1]\n",
    " - [Flattening JSON objects in Python][2]\n",
    " - [flatten package][3]\n",
    " - [How to flatten nested JSON recursively, with flatten_json?][4]\n",
    " - The `flatten_json` function, will be used to flatten `data`\n",
    " \n",
    "  [1]: https://realpython.com/python-thinking-recursively/\n",
    "  [2]: https://towardsdatascience.com/flattening-json-objects-in-python-f5343c794b10\n",
    "  [3]: https://github.com/amirziai/flatten\n",
    "  [4]: https://stackoverflow.com/questions/58442723/how-to-flatten-nested-json-recursively-with-flatten-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(nested_json: dict, exclude: list=[''], sep='_') -> dict:\n",
    "    \"\"\"\n",
    "    Flatten a list of nested dicts.\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    def flatten(x: (list, dict, str), name: str='', exclude=exclude):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                if a not in exclude:\n",
    "                    flatten(x[a], f'{name}{a}{sep}')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, f'{name}{i}{sep}')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(nested_json)\n",
    "    return out\n",
    "\n",
    "# df = pd.DataFrame([flatten_json(x) for x in data['Return']])\n",
    "# df = pd.DataFrame([flatten_json(x) for x in data[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_0 = pd.date_range(datetime.today(), periods=10).to_pydatetime().tolist()\n",
    "date_0[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_1 = pd.date_range(end=datetime.today(), periods=10).to_pydatetime().tolist()\n",
    "date_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.bdate_range(end=datetime.today(), periods=10).to_pydatetime().tolist()\n",
    "date[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sinusoidal Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinusoidal sample data\n",
    "sample_length = range(1, 14+1)\n",
    "rads = np.arange(0, 2*np.pi, 0.01)\n",
    "data = np.array([np.sin(t*rads) for t in sample_length])\n",
    "df = pd.DataFrame(data.T, index=pd.Series(rads.tolist(), name='radians'), columns=[f'freq: {i}x' for i in sample_length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date & Columns Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(365)\n",
    "rows = 2000\n",
    "data = {'date': pd.bdate_range('2021-06-09', freq='60s', periods=rows),\n",
    "        'a': np.random.randint(0, 3, size=(rows)),\n",
    "        'b': np.random.randint(15, 25, size=(rows)),\n",
    "        'c': np.random.randint(30, 40, size=(rows)),\n",
    "        'd': np.random.randint(450, 550, size=(rows)),\n",
    "        'e': np.random.randint(6000, 7000, size=(rows))}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 columns and a datetime index\n",
    "np.random.seed(365)\n",
    "rows = 30\n",
    "cols = 1\n",
    "df = pd.DataFrame(np.random.rand(rows, cols) * 1000, columns=list(string.ascii_lowercase[:cols]),\n",
    "                  index=pd.bdate_range(datetime.today(), freq='5min', periods=rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(365)\n",
    "rows = 1100\n",
    "data = {'date': pd.bdate_range(datetime.today(), freq='30min', periods=rows),\n",
    "        'a': np.random.randint(10, size=rows),\n",
    "        'groups': np.random.choice(['1-5', '6-25', '26-100', '100-500', '500-1000', '>1000'], size=rows),\n",
    "        'treatment': np.random.choice(['Yes', 'No'], size=rows)}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting stock data\n",
    "tickers = ['msft', 'aapl', 'twtr', 'intc', 'tsm', 'goog', 'amzn', 'fb', 'nvda']\n",
    "# tickers = ['^gspc']\n",
    "tickers = ['aapl']\n",
    "df_list = list()\n",
    "for ticker in tickers:\n",
    "#     df = web.DataReader(ticker, data_source='yahoo', start='1975-01-01', end='2020-09-28')\n",
    "    # df = web.DataReader(ticker, data_source='yahoo', start='1970-01-01', end='2022-06-13')\n",
    "    df = yf.download(ticker, start='2023-01-05', end='2023-01-06', interval='1h')\n",
    "    df['tkr'] = ticker\n",
    "    df_list.append(df)\n",
    "    \n",
    "df = pd.concat(df_list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['msft', 'aapl', 'intc', 'tsm', 'goog', 'amzn', 'meta', 'nvda']\n",
    "# tickers = ['^gspc']\n",
    "# tickers = ['aapl']\n",
    "\n",
    "# df = pd.concat((web.DataReader(ticker, data_source='yahoo', start='2020-01-01', end='2022-09-30').assign(tkr=ticker) for ticker in tickers), ignore_index=False)\n",
    "df = pd.concat((yf.download(ticker, start='2022-02-01', end='2023-07-14').assign(tkr=ticker) for ticker in tickers), ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stock data\n",
    "periods = '3600'\n",
    "resp = requests.get('https://api.cryptowat.ch/markets/poloniex/ethusdt/ohlc', params={'periods': periods})\n",
    "data = resp.json()\n",
    "df = pd.DataFrame(data['result'][periods], columns=['date', 'open', 'high', 'low', 'close', 'volume', 'amount'])\n",
    "df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "\n",
    "# stock = sdf.retype(df)\n",
    "# stock['macds']\n",
    "# stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('data.json')  # if in current dir\n",
    "# p = Path.cwd() / 'test.txt'\n",
    "# p = Path.cwd() / 'data/nvdcve-1.1-2019.json/nvdcve-1.1-2019.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with p.open('r', encoding='utf-8') as f:\n",
    "    data = json.loads(f.read())\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with a list of dicts\n",
    "with p.open(\"r\") as f:\n",
    "    data = literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read / Write Copied Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_clipboard(sep='\\s*\\|\\s*').iloc[1:,1:-1]  # read markdown into dataframe\n",
    "df = pd.read_clipboard(sep='\\\\s+') #, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard(sep='\\\\s+', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip.to_clipboard(sep=',', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "# df = pd.read_csv('test.txt', sep='|', header=None, converters={2: eval})  # converters={'file_path_lists': eval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']  # list a variables\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move legend outside\n",
    "ax.legend(bbox_to_anchor=(1, 0.5), loc='center left', frameon=False)\n",
    "sns.move_legend(ax, bbox_to_anchor=(1, 0.5), loc='center left', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib Inline / Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for interactive plots\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('d:/data/TrentonMcKinney_workouts.csv')\n",
    "df['Workout Timestamp'] = df['Workout Timestamp'].str.replace(' (PST)', '', regex=False).str.replace(' (-08)', '', regex=False).str.replace(' (-07)', '', regex=False)\n",
    "df['Workout Timestamp'] = pd.to_datetime(df['Workout Timestamp'])\n",
    "\n",
    "\n",
    "bins = [0, 9, 20, 30, 45, 60, 120]\n",
    "\n",
    "df['Length (minutes)'] = pd.cut(df['Length (minutes)'], bins=bins)\n",
    "\n",
    "\n",
    "# df = df[~df['Length (minutes)'].le(9)].copy()\n",
    "df = df.sort_values('Workout Timestamp', ignore_index=True)\n",
    "# df['Length (minutes)'] = df['Length (minutes)'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Length (minutes)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fitness Discipline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {disc: df[df['Fitness Discipline'].eq(disc)].reset_index(drop=True).copy() for disc in df['Fitness Discipline'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd['Cycling'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = dd['Cycling'][['Workout Timestamp', 'Avg. Watts']].set_index('Workout Timestamp').rolling('3D').mean()\n",
    "rm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(kind='line', data=dd['Cycling'], x='Workout Timestamp', y='Avg. Watts', hue='Length (minutes)', aspect=1.5, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(kind='line', data=dd['Cycling'], x='Workout Timestamp', y='Total Output', hue='Length (minutes)', aspect=1.5, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib-3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed tag(s) from the title, as per https://meta.stackexchange.com/help/tagging. Removed ? because the title is not a question; it's missing an auxiliary verb (e.g. How do I ...?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
